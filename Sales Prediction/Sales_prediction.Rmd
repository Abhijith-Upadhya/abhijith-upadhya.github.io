---
title: ""
author: "Abhijith"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# **Sales Forecasting - Timeseries**

![Source: HPT PEDIA.](http://hptpedia.hyper-trade.com/content/images/2023/08/Sales-forecast.jpg)

## 1. Introduction

This report presents an analysis of sales data and the development of forecasting models to predict future sales. We'll explore the dataset, perform exploratory data analysis, and compare different forecasting models to determine the most effective approach for predicting sales.

## 2. Loading Dataset

First, we'll load the necessary libraries and the dataset.

```{r setup, message=FALSE, warning=FALSE}
library(tidyverse)
library(lubridate)
library(ggplot2)
library(forecast)
library(randomForest)
library(xgboost)
library(readr)
library(dplyr)
library(randomForest)
library(xgboost)
library(stats)
library(stringr)
library(forecast)
library(gridExtra)

# Load the dataset
train_data <- read.csv("train.csv")
```

## 3. Data Exploration

Let's take a look at the structure and summary of our dataset.

```{r data_exploration}
str(train_data)
summary(train_data$sales)
```

## 4. Exploratory Data Analysis

Now, we'll visualize the sales data to understand patterns and trends.

```{r eda, fig.width=10, fig.height=6}
# Plot sales over time
ggplot(train_data, aes(x = date, y = sales)) +
  geom_line() +
  theme_minimal() +
  labs(title = "Sales Over Time", x = "Date", y = "Sales")

# Function to aggregate sales by month or year
monthlyORyears_sales <- function(data, time = c("monthly", "years")) {
  data %>%
    mutate(date = as.Date(date)) %>%
    group_by(date = if(time == "monthly") floor_date(date, "month") else floor_date(date, "year")) %>%
    summarise(sales = sum(sales, na.rm = TRUE)) %>%
    ungroup()
}

# Monthly and yearly sales
m_df <- monthlyORyears_sales(train_data, "monthly")
y_df <- monthlyORyears_sales(train_data, "years")

# Plot yearly and monthly sales
p1 <- ggplot(y_df, aes(x = date, y = sales)) +
  geom_bar(stat = "identity", fill = "mediumblue") +
  labs(title = "Distribution of Sales Per Year", x = "Years", y = "Sales") +
  theme_minimal()

p2 <- ggplot(m_df, aes(x = date, y = sales)) +
  geom_line(color = "darkorange") +
  geom_point(color = "darkorange") +
  labs(title = "Distribution of Sales Per Month", x = "Months", y = "Sales") +
  theme_minimal()

grid.arrange(p1, p2, ncol = 2)
```

## 5. Train and Test Split

We'll prepare the data for our forecasting models by creating training and test sets.

```{r train_test_split}
# For yearly models
yearly_sales <- train_data %>%
  mutate(year = year(as.Date(date))) %>%
  group_by(year) %>%
  summarise(total_sales = sum(sales)) %>%
  filter(year >= 2013 & year <= 2018)

# For monthly models
monthly_sales <- train_data %>%
  mutate(date = as.Date(date)) %>%
  filter(year(date) >= 2013 & year(date) <= 2018) %>%
  group_by(date = floor_date(date, "month")) %>%
  summarise(total_sales = sum(sales))

# Convert to time series object for ARIMA and SARIMA
sales_ts <- ts(monthly_sales$total_sales, start = c(2013, 1), frequency = 12)
```

## 6. Forecasting Models

We'll implement and evaluate several forecasting models:

1. Random Forest
2. XGBoost
3. Linear Regression
4. ARIMA
5. SARIMA

### 6.1 Random Forest

```{r random_forest, fig.width=10, fig.height=6}
rf_model <- randomForest(total_sales ~ year, data = yearly_sales, ntree = 500)
rf_predictions <- predict(rf_model, newdata = data.frame(year = yearly_sales$year))

ggplot(yearly_sales, aes(x = year)) +
  geom_line(aes(y = total_sales, color = "Actual Sales"), size = 1) +
  geom_line(aes(y = rf_predictions, color = "Projected Sales"), size = 1) +
  geom_point(aes(y = total_sales, color = "Actual Sales"), size = 3) +
  geom_point(aes(y = rf_predictions, color = "Projected Sales"), size = 3) +
  scale_color_manual(values = c("Actual Sales" = "blue", "Projected Sales" = "red")) +
  labs(title = "Yearly Sales Projection using Random Forest (2013-2018)",
       x = "Year", y = "Total Sales", color = "Legend") +
  theme_minimal()
```

### 6.2 XGBoost

```{r xgboost, fig.width=10, fig.height=6, include=FALSE}
dtrain <- xgb.DMatrix(data = as.matrix(yearly_sales["year"]), label = yearly_sales$total_sales)
params <- list(objective = "reg:squarederror", eta = 0.1, max_depth = 3, nrounds = 100)
xgb_model <- xgb.train(params = params, data = dtrain, nrounds = 100)
xgb_predictions <- predict(xgb_model, as.matrix(yearly_sales["year"]))

ggplot(yearly_sales, aes(x = year)) +
  geom_line(aes(y = total_sales, color = "Actual Sales"), size = 1) +
  geom_line(aes(y = xgb_predictions, color = "Projected Sales"), size = 1) +
  geom_point(aes(y = total_sales, color = "Actual Sales"), size = 3) +
  geom_point(aes(y = xgb_predictions, color = "Projected Sales"), size = 3) +
  scale_color_manual(values = c("Actual Sales" = "blue", "Projected Sales" = "red")) +
  labs(title = "Yearly Sales Projection using XGBoost (2013-2018)",
       x = "Year", y = "Total Sales", color = "Legend") +
  theme_minimal()
```

### 6.3 Linear Regression

```{r linear_regression, fig.width=10, fig.height=6}
lm_model <- lm(total_sales ~ year, data = yearly_sales)
lm_predictions <- predict(lm_model, newdata = yearly_sales)

ggplot(yearly_sales, aes(x = year)) +
  geom_line(aes(y = total_sales, color = "Actual Sales"), size = 1) +
  geom_line(aes(y = lm_predictions, color = "Projected Sales"), size = 1) +
  geom_point(aes(y = total_sales, color = "Actual Sales"), size = 3) +
  geom_point(aes(y = lm_predictions, color = "Projected Sales"), size = 3) +
  scale_color_manual(values = c("Actual Sales" = "blue", "Projected Sales" = "red")) +
  labs(title = "Yearly Sales Projection using Linear Regression (2013-2018)",
       x = "Year", y = "Total Sales", color = "Legend") +
  theme_minimal()
```

### 6.4 ARIMA

```{r arima, fig.width=10, fig.height=6, include=FALSE}
arima_model <- auto.arima(sales_ts, seasonal = FALSE)
arima_forecast <- forecast(arima_model, h = 12)

autoplot(arima_forecast) +
  autolayer(sales_ts, series = "Actual") +
  labs(title = "ARIMA Sales Forecast (2013-2018)", y = "Sales", x = "Year") +
  theme_minimal()
```

### 6.5 SARIMA

```{r sarima, fig.width=10, fig.height=6}
sarima_model <- auto.arima(sales_ts, seasonal = TRUE)
sarima_forecast <- forecast(sarima_model, h = 12)

autoplot(sarima_forecast) +
  autolayer(sales_ts, series = "Actual") +
  labs(title = "SARIMA Sales Forecast (2013-2018)", y = "Sales", x = "Year") +
  theme_minimal()
```

## 7. Model Comparison

Let's compare the performance of our models using various metrics.

```{r model_comparison}
calculate_metrics <- function(actual, predicted) {
  mse <- mean((actual - predicted)^2, na.rm = TRUE)
  rmse <- sqrt(mse)
  mae <- mean(abs(actual - predicted), na.rm = TRUE)
  r_squared <- 1 - sum((actual - predicted)^2) / sum((actual - mean(actual))^2)
  
  c(MSE = mse, RMSE = rmse, MAE = mae, R_squared = r_squared)
}

rf_metrics <- calculate_metrics(yearly_sales$total_sales, rf_predictions)
xgb_metrics <- calculate_metrics(yearly_sales$total_sales, xgb_predictions)
lm_metrics <- calculate_metrics(yearly_sales$total_sales, lm_predictions)
arima_metrics <- calculate_metrics(sales_ts, arima_model$fitted)
sarima_metrics <- calculate_metrics(sales_ts, sarima_model$fitted)

metrics_df <- data.frame(
  Model = c("Random Forest", "XGBoost", "Linear Regression", "ARIMA", "SARIMA"),
  rbind(rf_metrics, xgb_metrics, lm_metrics, arima_metrics, sarima_metrics)
)

knitr::kable(metrics_df, digits = 2)
```

## 8. Conclusion

Based on our analysis and comparison of different forecasting models, we can draw the following conclusions:

1. All models show reasonably good performance in predicting sales, with R-squared values generally above 0.8.

2. The Random Forest and XGBoost models perform particularly well for yearly sales predictions, showing high R-squared values and low error metrics.

3. For monthly sales forecasting, both ARIMA and SARIMA models provide good results, with SARIMA potentially capturing seasonal patterns better.

4. The Linear Regression model, while simple, still provides a decent baseline for yearly sales predictions.

5. The choice of the best model may depend on the specific use case:
   - For long-term yearly predictions, Random Forest or XGBoost might be preferred.
   - For monthly forecasts with seasonal components, SARIMA could be the best choice.
   - If interpretability is important, the Linear Regression model offers a good balance of simplicity and performance.

6. Further improvements could be made by:
   - Incorporating more features (e.g., economic indicators, marketing spend) into the models.
   - Experimenting with ensemble methods that combine multiple models.
   - Conducting cross-validation to ensure model stability and generalizability.

In conclusion, this analysis provides a solid foundation for sales forecasting, offering multiple models that can be chosen based on the specific requirements of the business.
