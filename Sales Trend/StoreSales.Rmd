---
title: "StoreSales"
author: "Abhijith Upadhya"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

## Introduction

This document presents a comprehensive analysis of sales data, focusing on trends, correlations, and forecasting using R. We will utilize various libraries for data manipulation, visualization, and modeling.

## Setup

First, we need to install and load the necessary packages.

```{r setup1, message=FALSE, warning=FALSE}
# Load libraries
library(Metrics)
library(zoo)
library(viridis)
library(reshape2)
library(tseries)
library(gridExtra)
library(forecast)
library(xgboost)
library(caret)
library(randomForest)
library(GGally)
library(corrplot)
library(tidyverse)
library(dplyr)
library(ggplot2)
library(lubridate)
library(tidyr)

store <- read.csv('store.csv')
train <- read.csv('train.csv') %>%
  mutate(Date = as.Date(Date)) %>%
  arrange(Date)
```

## Data Loading

We will load the datasets for store and training data.

```{r data_loading}
# Display the first few rows of each dataset
print("Store data:")
print(head(store))
print("\nTrain data:")
print(head(train))
```

## Data Preparation

Next, we merge the training data with store data and extract year and month from the date.


```{r data_preparation}
# Merge train and store data
train_store_joined <- inner_join(train, store, by = "Store")

# Extract month and year from the date
train_store_joined <- train_store_joined %>%
  mutate(Year = year(Date),
         Month = month(Date))
```

## Sales Summary by Month

We summarize sales data by month and create a line plot with error bars.

```{r sales_summary_by_month, fig.width=10, fig.height=6}
sales_summary <- train_store_joined %>%
  group_by(Year, Month, Promo, Promo2) %>%
  summarise(
    mean_sales = mean(Sales, na.rm = TRUE),
    se_sales = sd(Sales, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Create the line plot with error bars
sales_trend_plot <- ggplot(sales_summary, aes(x = factor(Month), y = mean_sales, group = interaction(Year, Promo2), color = factor(Promo2))) +
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin = mean_sales - se_sales, ymax = mean_sales + se_sales), width = 0.2) +
  facet_grid(Year ~ Promo) +
  labs(title = "Average Sales Trend by Month, Year, and Promotions",
       x = "Month", y = "Average Sales", color = "Promo2") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  scale_color_discrete(name = "Promo2", labels = c("No", "Yes"))

# Print the plot
print(sales_trend_plot)
```

## Sales Summary by Day of Week

Next, we analyze sales trends over the days of the week.

```{r sales_summary_by_day, fig.width=10, fig.height=6}
sales_summary_weekday <- train_store_joined %>%
  group_by(DayOfWeek, Promo) %>%
  summarise(
    mean_sales = mean(Sales, na.rm = TRUE),
    se_sales = sd(Sales, na.rm = TRUE) / sqrt(n()),
    .groups = 'drop'
  )

# Create the plot for sales trend over days of week
sales_trend_weekday_plot <- ggplot(sales_summary_weekday, aes(x = factor(DayOfWeek), y = mean_sales, group = factor(Promo), color = factor(Promo))) +
  geom_line(size = 1.2) +
  geom_point(size = 3, shape = 21, fill = "white") +
  geom_errorbar(aes(ymin = mean_sales - se_sales, ymax = mean_sales + se_sales), width = 0.2, alpha = 0.7) +
  labs(
    title = "Sales Trend Over Days of Week",
    subtitle = "Comparing sales with and without promotions",
    x = "Day of Week", 
    y = "Average Sales", 
    color = "Promotion Status"
  ) +
  scale_x_discrete(labels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun")) +
  scale_y_continuous(labels = scales::comma_format(scale = 1e-3, suffix = "K")) +
  scale_color_viridis(discrete = TRUE) +
  theme_minimal(base_size = 14)

# Print the plot
print(sales_trend_weekday_plot)
```

## Correlation Analysis

We analyze correlations between key features using a heatmap.

```{r correlation_analysis, fig.width=10, fig.height=6}
correlation_matrix <- train_store_joined %>%
  select(Sales, Customers, Promo, SchoolHoliday, CompetitionDistance) %>%
  cor()

corr_melted <- melt(correlation_matrix)

# Create the correlation heatmap
correlation_plot <- ggplot(corr_melted, aes(x = Var1, y = Var2, fill = value)) +
  geom_tile(color = "white") +
  geom_text(aes(label = sprintf("%.2f", value)), 
            color = ifelse(abs(corr_melted$value) > 0.5, "white", "black"), 
            size=3.5) +
  scale_fill_viridis(option="C") +
  coord_equal() +
  theme_minimal() +
  labs(
    title="Correlation Heatmap of Key Features",
    subtitle="Strength and direction of relationships between variables",
    x="", 
    y=""
  )

# Print the plot
print(correlation_plot)
```

## Time Series Analysis

We will perform time series analysis on weekly sales.

# Weekly Sales Calculation

```{r weekly_sales_calculation}
sales_a <- train %>% 
  filter(Store == 2) %>%
  select(Date, Sales) %>%
  arrange(Date)

weekly_sales_a <- sales_a %>%
  mutate(week=as.Date(cut(Date, breaks="week"))) %>%
  group_by(week) %>%
  summarise(Sales=sum(Sales))
```

## Stationarity Check

We will check for stationarity in our time series data.

```{r stationarity_check}
test_stationarity <- function(timeseries) {
  
   # Perform Dickey-Fuller test
   adf_test <- adf.test(timeseries$Sales)

   # Output results of Dickey-Fuller test
   print("Results of Dickey-Fuller Test:")
   print(paste("ADF Statistic: ", adf_test$statistic))
   print(paste("p-value: ", adf_test$p.value))

   if(adf_test$p.value < 0.05) {
     print("Data is stationary (Reject the null hypothesis)")
   } else {
     print("Data is not stationary (Fail to reject the null hypothesis)")
   }
}

# Testing stationarity for Store Type 'a'
test_stationarity(weekly_sales_a)
```

## Decomposition Plot

We will visualize the trend and seasonality in our time series data.

```{r decomposition_plot, fig.width=10, fig.height=6}
plot_timeseries <- function(sales) {
   ts_data <- ts(sales$Sales, frequency=52)

   # Perform decomposition
   decomp <- stl(ts_data,s.window="periodic")
   
   # Plot decomposition
   plot(decomp)
}

# Plot decomposition for Store Type 'a'
plot_timeseries(weekly_sales_a)
```

## ARIMA Model Fitting

We will fit an ARIMA model to forecast future sales.

```{r ARIMA_model, fig.width=10, fig.height=6}
weekly_sales_ts <- ts(weekly_sales_a$Sales, frequency=52)

fit_arima <- auto.arima(weekly_sales_ts)

# Print ARIMA model summary
summary(fit_arima)

forecasted_sales <- forecast(fit_arima,h=12)

# Plot the forecasted sales
plot(forecasted_sales)
```


## Conclusion

In this analysis, we explored sales trends, examined correlations between variables, and built forecasting models using both ARIMA and XGBoost approaches. These insights can help in understanding sales patterns and making informed business decisions.

